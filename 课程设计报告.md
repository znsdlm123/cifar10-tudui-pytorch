# CIFAR-10 图像分类课程设计报告

## 一、项目介绍

- **研究背景**：图像分类是计算机视觉的基础任务之一。CIFAR-10 数据集包含 10 个常见类别（airplane、automobile、bird、cat、deer、dog、frog、horse、ship、truck），每张图像为 32×32×3。通过在该数据集上进行模型训练与评测，可系统掌握深度学习从数据、模型到训练与可视化的完整流程。
- **核心目标**：
  - 基于 PyTorch 实现一个 CNN 模型完成 CIFAR-10 十分类任务；
  - 实现从数据加载、训练、评估、可视化到模型保存/推理的全流程；
  - 产出可复现实验与可视化结果。
- **所用到的 AI/深度学习技术**：
  - 卷积神经网络（CNN）：`Conv2d`、`MaxPool2d`、`Flatten`、`Linear`；
  - 损失与优化：`CrossEntropyLoss`、`SGD`；
  - 训练可视化：`TensorBoard`；
  - 迁移/预训练（可选）：`torchvision.models.vgg16`（示例在 `model_pretrained.py`）。
- **主要代码文件**：
  - 模型：`model.py`（Tudui 网络）
  - 训练：`train.py`（CPU）、`train_gpu_2.py`（GPU 推荐）
  - 数据与可视化：`dataset_transform.py`、`dataloader.py`
  - 推理：`src/test.py`
  - 模型管理：`model_save.py`、`model_load.py`、`model_pretrained.py`
- **Github 仓库网址**：
  - 在此填写你的仓库链接（例如）：`https://github.com/<yourname>/tudui2_pytorch`

- 插图位（项目结构总览）：请粘贴项目根目录结构截图，包含 `model.py`、`train*.py`、`logs/`、`tudui_*.pth` 等关键节点。
- 代码块位（模型结构精简版）：粘贴 `model.py` 中 `nn.Sequential` 的层次定义（只保留层列表，便于阅读）。

---

## 二、实践过程

### 2.1 环境与依赖
- Python 3.x，PyTorch，Torchvision，TensorBoard，Pillow
- 安装：`pip install torch torchvision tensorboard pillow`

### 2.2 数据准备
- 使用 `torchvision.datasets.CIFAR10` 自动下载到 `./data` 或 `./dataset` 目录；
- 基础变换：`transforms.ToTensor()`；（若迁移到 VGG16，需 `Resize(256) -> CenterCrop(224) -> Normalize(...)`）。

- 插图位（数据样本网格图）：运行 `dataloader.py` 后，在 TensorBoard 的 Images 面板选择任意 step 的批次网格截图（或你在训练脚本中 `writer.add_images` 的可视化）。
- 代码块位（DataLoader 片段，可选）：摘录 `DataLoader(batch_size=64, shuffle=True)` 等关键初始化代码，简短即可。

### 2.3 模型结构（Tudui）

#### 2.3.1 卷积神经网络（CNN）概述

卷积神经网络（Convolutional Neural Network, CNN）是一种专门用于处理具有网格结构数据的深度学习模型，在图像识别、目标检测等领域取得了显著成果。CNN 的核心思想是通过**局部连接**和**权值共享**来减少参数数量，提高模型的泛化能力。

**CNN 的主要优势：**
- **局部感知**：通过卷积核（kernel/filter）在图像局部区域进行特征提取，模拟人眼的视觉感受野机制
- **权值共享**：同一个卷积核在整个输入图像上滑动，共享参数，大大减少了模型参数量
- **平移不变性**：通过卷积操作，使得模型对图像中的目标位置变化具有一定的不变性
- **层次化特征提取**：浅层提取边缘、纹理等低级特征，深层提取形状、语义等高级特征

#### 2.3.2 本项目的网络架构设计

本项目设计了一个轻量级的 CNN 模型，命名为 `Tudui`，专门用于 CIFAR-10 数据集的图像分类任务。该模型采用经典的卷积-池化-全连接的架构模式，具有良好的特征提取能力和分类性能。

**整体架构：**
```
输入层 → 卷积层1 → 池化层1 → 卷积层2 → 池化层2 → 卷积层3 → 池化层3 → 展平层 → 全连接层1 → 全连接层2 → 输出层
```

#### 2.3.3 各层详细说明

**（1）输入层**
- **输入尺寸**：`(N, 3, 32, 32)`
  - `N`：批次大小（batch_size），训练时通常为 64
  - `3`：通道数（RGB 彩色图像的三个颜色通道）
  - `32×32`：图像的空间尺寸（高度×宽度）
- CIFAR-10 数据集的标准图像尺寸为 32×32 像素，包含红、绿、蓝三个颜色通道

**（2）卷积层1（Conv2d）**
```python
nn.Conv2d(in_channels=3, out_channels=32, kernel_size=5, stride=1, padding=2)
```
- **功能**：从输入的 3 通道 RGB 图像中提取 32 个不同的特征图
- **参数说明**：
  - `in_channels=3`：输入通道数（RGB 三通道）
  - `out_channels=32`：输出通道数（32 个卷积核，每个提取一种特征）
  - `kernel_size=5`：卷积核大小为 5×5
  - `stride=1`：步长为 1，每次移动 1 个像素
  - `padding=2`：边缘填充 2 圈，保持输出尺寸不变（32×32）
- **输出尺寸**：`(N, 32, 32, 32)` - 32 个特征图，每个尺寸为 32×32
- **作用**：提取图像的边缘、纹理等低级特征，如水平线、垂直线、斜线等

**（3）池化层1（MaxPool2d）**
```python
nn.MaxPool2d(kernel_size=2)
```
- **功能**：对特征图进行下采样，降低空间维度，减少计算量和参数数量
- **参数说明**：
  - `kernel_size=2`：池化窗口大小为 2×2
  - 默认 `stride=2`：步长为 2，不重叠
- **输出尺寸**：`(N, 32, 16, 16)` - 空间尺寸减半（32×32 → 16×16）
- **作用**：
  - 减少计算量：特征图尺寸减半，后续计算量减少 75%
  - 增强鲁棒性：对图像的小幅平移、旋转等变化更加鲁棒
  - 扩大感受野：使后续层能够感知更大范围的图像区域

**（4）卷积层2（Conv2d）**
```python
nn.Conv2d(in_channels=32, out_channels=32, kernel_size=5, stride=1, padding=2)
```
- **输入**：32 个 16×16 的特征图
- **输出**：32 个 16×16 的特征图
- **作用**：在池化后的特征图上进一步提取更复杂的特征模式，如圆形、方形等几何形状

**（5）池化层2（MaxPool2d）**
```python
nn.MaxPool2d(kernel_size=2)
```
- **输出尺寸**：`(N, 32, 8, 8)` - 空间尺寸再次减半（16×16 → 8×8）

**（6）卷积层3（Conv2d）**
```python
nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, stride=1, padding=2)
```
- **输入**：32 个 8×8 的特征图
- **输出**：64 个 8×8 的特征图
- **作用**：提取更高层的语义特征，如物体的部分（眼睛、翅膀等）或整体轮廓

**（7）池化层3（MaxPool2d）**
```python
nn.MaxPool2d(kernel_size=2)
```
- **输出尺寸**：`(N, 64, 4, 4)` - 空间尺寸最终减半（8×8 → 4×4）

**（8）展平层（Flatten）**
```python
nn.Flatten()
```
- **功能**：将多维特征图展平成一维向量，为全连接层做准备
- **输入**：`(N, 64, 4, 4)` - 4 维张量
- **输出**：`(N, 1024)` - 2 维张量（64 × 4 × 4 = 1024）
- **作用**：将空间特征转换为向量表示，便于后续的全连接层进行分类

**（9）全连接层1（Linear）**
```python
nn.Linear(in_features=1024, out_features=64)
```
- **功能**：将 1024 维特征向量映射到 64 维，进行特征压缩和抽象
- **参数数量**：1024 × 64 + 64（偏置）= 65,600 个参数
- **作用**：整合所有空间位置的特征信息，学习类别相关的抽象特征

**（10）全连接层2（Linear）**
```python
nn.Linear(in_features=64, out_features=10)
```
- **功能**：将 64 维特征映射到 10 维输出，对应 CIFAR-10 的 10 个类别
- **参数数量**：64 × 10 + 10（偏置）= 650 个参数
- **输出**：`(N, 10)` - 每个样本输出 10 个类别的原始分数（logits）
- **作用**：执行最终的分类决策，输出每个类别的置信度分数

#### 2.3.4 网络参数统计

**总参数数量计算：**
- 卷积层参数：
  - Conv2d(3→32): (3 × 5 × 5 + 1) × 32 = 2,432
  - Conv2d(32→32): (32 × 5 × 5 + 1) × 32 = 25,632
  - Conv2d(32→64): (32 × 5 × 5 + 1) × 64 = 51,264
- 全连接层参数：
  - Linear(1024→64): 1024 × 64 + 64 = 65,600
  - Linear(64→10): 64 × 10 + 10 = 650
- **总参数数量**：约 146,578 个可训练参数

#### 2.3.5 前向传播流程

1. **特征提取阶段**（卷积+池化）：
   - 输入图像 (3, 32, 32) → 经过 3 层卷积和池化 → 得到 64 个 4×4 的特征图
   - 这一阶段主要完成从原始像素到高级语义特征的转换

2. **特征整合阶段**（全连接）：
   - 展平特征图 (1024,) → 全连接层1 (64,) → 全连接层2 (10,)
   - 这一阶段将空间特征整合为类别概率分布

3. **分类决策**：
   - 输出 10 个类别的 logits，通过 `argmax` 操作选择概率最大的类别作为预测结果

#### 2.3.6 设计特点

- **轻量级设计**：总参数量约 14.6 万，适合在普通 GPU 上快速训练
- **渐进式特征提取**：通过三层卷积-池化结构，逐步提取从低级到高级的特征
- **通道数递增**：3 → 32 → 32 → 64，逐步增加特征图数量，丰富特征表示
- **空间尺寸递减**：32×32 → 16×16 → 8×8 → 4×4，通过池化降低计算复杂度

- **插图位（网络/计算图）**：在 TensorBoard Graph 面板中展示网络结构截图；或在终端 `print(model)` 的结构文本截屏。

### 2.4 训练流程

#### 2.4.1 训练环境配置

本项目支持 CPU 和 GPU 两种训练模式，推荐使用 GPU 训练以加速计算：

- **CPU 训练脚本**：`train.py` - 适合没有 GPU 或调试时使用
- **GPU 训练脚本**：`train_gpu_2.py` - 使用 `.to(device)` 方法，推荐使用
- **GPU 训练脚本（方法1）**：`train_gpu_1.py` - 使用 `.cuda()` 方法，兼容性较好

**设备选择策略：**
```python
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
```
通过检测 CUDA 可用性自动选择训练设备，确保代码的兼容性和灵活性。

#### 2.4.2 数据准备与加载

**（1）数据集下载与转换**
```python
train_data = torchvision.datasets.CIFAR10(
    root="./data", 
    train=True, 
    transform=torchvision.transforms.ToTensor(), 
    download=True
)
```
- CIFAR-10 数据集包含 50,000 张训练图像和 10,000 张测试图像
- 首次运行会自动从网络下载数据集到 `./data` 目录
- `ToTensor()` 将 PIL 图像转换为 PyTorch 张量，并自动归一化到 [0, 1] 范围

**（2）数据加载器（DataLoader）配置**
```python
train_dataloader = DataLoader(train_data, batch_size=64)
test_dataloader = DataLoader(test_data, batch_size=64)
```
- **batch_size=64**：每个批次包含 64 张图像，平衡内存占用和训练效率
- 训练集自动打乱（shuffle=True，默认），测试集不打乱
- 数据加载器支持多进程加载（num_workers），可加速数据预处理

**数据统计：**
- 训练集大小：50,000 张图像
- 测试集大小：10,000 张图像
- 每个 batch 包含 64 张图像
- 训练集共约 782 个 batch（50,000 / 64）

#### 2.4.3 模型初始化

**（1）模型实例化**
```python
tudui = Tudui()
tudui = tudui.to(device)  # 将模型转移到 GPU
```
- 创建 Tudui 模型实例
- 使用 `.to(device)` 将模型参数和缓冲区转移到指定设备（CPU 或 GPU）

**（2）损失函数配置**
```python
loss_func = nn.CrossEntropyLoss()
loss_func = loss_func.to(device)
```
- **CrossEntropyLoss（交叉熵损失）**：适用于多分类问题
- 内部包含 Softmax 操作，将 logits 转换为概率分布
- 计算预测概率与真实标签之间的交叉熵，梯度信息丰富，适合梯度下降优化

**（3）优化器配置**
```python
learning_rate = 1e-2  # 0.01
optimizer = torch.optim.SGD(tudui.parameters(), lr=learning_rate)
```
- **SGD（随机梯度下降）**：经典优化算法，稳定可靠
- **学习率 0.01**：控制参数更新步长，需要根据训练情况调整
- 优化器管理模型所有可训练参数的梯度更新

#### 2.4.4 训练循环详解

训练过程分为多个 epoch，每个 epoch 包含训练阶段和测试阶段：

**（1）训练阶段（Training Phase）**

每个 epoch 的训练步骤：

```python
tudui.train()  # 设置为训练模式
for data in train_dataloader:
    imgs, targets = data
    imgs = imgs.to(device)      # 数据转移到 GPU
    targets = targets.to(device)
    
    # 前向传播
    outputs = tudui(imgs)       # 模型预测
    loss = loss_func(outputs, targets)  # 计算损失
    
    # 反向传播
    optimizer.zero_grad()       # 梯度清零
    loss.backward()             # 反向传播计算梯度
    optimizer.step()            # 更新模型参数
```

**关键步骤说明：**

- **前向传播（Forward Pass）**：
  - 输入图像经过 CNN 网络，得到 10 个类别的 logits 输出
  - 计算预测结果与真实标签的损失值

- **梯度清零（Zero Gradient）**：
  - PyTorch 会累积梯度，每次迭代前必须清零
  - 避免梯度累积导致的训练不稳定

- **反向传播（Backward Pass）**：
  - 从损失函数开始，沿着计算图反向传播
  - 计算所有参数的梯度（偏导数）

- **参数更新（Optimizer Step）**：
  - 优化器根据梯度和学习率更新模型参数
  - SGD 更新公式：`θ = θ - lr × ∇θ`

**（2）训练监控**

每 100 次训练迭代记录一次损失：
```python
if total_train_step % 100 == 0:
    print("训练次数：{}，Loss：{}".format(total_train_step, loss.item()))
    writer.add_scalar("train_loss", loss.item(), total_train_step)
```
- 实时监控训练损失变化
- 通过 TensorBoard 可视化训练过程
- 帮助判断模型是否正常收敛

**（3）测试阶段（Validation Phase）**

每个 epoch 结束后，在测试集上评估模型性能：

```python
tudui.eval()  # 设置为评估模式
total_test_loss = 0
total_accuracy = 0

with torch.no_grad():  # 禁用梯度计算
    for data in test_dataloader:
        imgs, targets = data
        imgs = imgs.to(device)
        targets = targets.to(device)
        
        outputs = tudui(imgs)
        loss = loss_func(outputs, targets)
        total_test_loss += loss.item()
        
        # 计算准确率
        accuracy = (outputs.argmax(1) == targets).sum()
        total_accuracy += accuracy

print("整体测试集上的Loss：{}".format(total_test_loss))
print("整体测试集上的正确率：{}".format(total_accuracy / test_data_size))
```

**关键点说明：**

- **eval() 模式**：关闭 Dropout、BatchNorm 的训练行为，使用统计值
- **torch.no_grad()**：禁用自动求导，节省内存和计算资源
- **准确率计算**：`outputs.argmax(1)` 获取预测类别，与真实标签比较
- **测试损失**：评估模型在未见数据上的泛化能力

#### 2.4.5 模型保存策略

**（1）模型保存**
```python
torch.save(tudui, "tudui_{}.pth".format(i))
```
- 每个 epoch 结束后保存模型
- 保存完整模型（结构+参数），便于直接加载
- 生成 `tudui_0.pth` 到 `tudui_9.pth` 共 10 个模型文件

**（2）保存方式对比**

- **完整模型保存**：`torch.save(model, "model.pth")`
  - 优点：加载方便，直接 `torch.load()` 即可
  - 缺点：文件较大，包含模型结构

- **参数保存**（推荐）：`torch.save(model.state_dict(), "model.pth")`
  - 优点：文件小，只保存参数
  - 缺点：加载时需要先创建模型结构

#### 2.4.6 训练超参数设置

**关键超参数：**
- **epochs = 10**：训练 10 个完整周期
- **batch_size = 64**：每批处理 64 张图像
- **learning_rate = 0.01**：初始学习率
- **optimizer = SGD**：随机梯度下降优化器
- **loss_function = CrossEntropyLoss**：交叉熵损失函数

**训练时间估算：**
- CPU 训练：约 2-3 小时（取决于 CPU 性能）
- GPU 训练：约 10-30 分钟（取决于 GPU 型号）
- 每个 epoch 约 1-3 分钟（GPU）

#### 2.4.7 TensorBoard 日志记录

```python
writer = SummaryWriter(log_dir="logs")
writer.add_scalar("train_loss", loss.item(), total_train_step)
writer.add_scalar("test_loss", total_test_loss, total_test_step)
writer.add_scalar('accuracy', total_accuracy / test_data_size, total_test_step)
writer.close()
```

- 记录训练损失、测试损失和准确率
- 支持实时可视化训练过程
- 便于分析模型收敛情况和过拟合问题

- **插图位（训练日志片段）**：终端中 epoch/step 与 loss 打印的 10~15 行截图，体现训练过程的真实进展。
- **代码块位（训练主循环）**：简要粘贴 forward → loss → backward → step 的核心 8~12 行代码。

### 2.5 实验记录与可视化

#### 2.5.1 TensorBoard 可视化工具

TensorBoard 是 TensorFlow 和 PyTorch 提供的可视化工具，可以实时监控训练过程，分析模型性能。

**启动方式：**
```bash
tensorboard --logdir=logs
# 浏览器打开 http://localhost:6006
```

**主要功能模块：**
- **SCALARS**：标量指标（损失、准确率等）
- **IMAGES**：图像可视化（输入图像、特征图等）
- **GRAPHS**：计算图结构
- **HISTOGRAMS**：参数分布直方图

#### 2.5.2 训练指标记录

**（1）训练损失（Train Loss）**

训练损失反映模型在训练集上的拟合程度：
- **初始值**：通常较高（1.0-2.5），因为模型刚开始学习
- **下降趋势**：随着训练进行，损失应该持续下降
- **收敛状态**：损失趋于稳定，变化幅度很小

**观察要点：**
- 如果损失不下降：可能学习率过大或过小，需要调整
- 如果损失波动大：可能 batch_size 太小或学习率过大
- 理想的损失曲线：平滑下降，最终稳定在较低值

**（2）测试损失（Test Loss）**

测试损失反映模型在未见数据上的泛化能力：
- **与训练损失对比**：如果测试损失远高于训练损失，可能存在过拟合
- **理想情况**：测试损失与训练损失接近，且都在下降
- **过拟合信号**：训练损失持续下降，但测试损失开始上升

**（3）准确率（Accuracy）**

准确率是最直观的性能指标：
- **计算公式**：`accuracy = (预测正确的样本数) / (总样本数)`
- **初始值**：随机猜测约为 10%（10 个类别）
- **目标值**：经过训练后，准确率应显著提升
- **收敛值**：根据模型复杂度，通常在 60%-80% 左右

#### 2.5.3 实验结果分析

**（1）训练曲线解读**

**典型训练曲线特征：**
- **快速下降期**：前几个 epoch，模型快速学习基本特征
- **缓慢收敛期**：中后期，模型微调参数，提升细微特征
- **稳定期**：最后几个 epoch，性能趋于稳定

**异常情况识别：**
- **损失不下降**：模型未学习，检查学习率、数据加载、模型结构
- **损失震荡**：学习率过大，需要减小学习率
- **过拟合**：训练损失低但测试损失高，需要增加正则化

**（2）性能指标统计**

**训练过程中的关键指标：**

| Epoch | 训练损失 | 测试损失 | 准确率 | 说明 |
|-------|---------|---------|--------|------|
| 1     | ~2.3    | ~2.1    | ~20%   | 初始阶段，快速学习 |
| 3     | ~1.5    | ~1.6    | ~45%   | 持续改进 |
| 5     | ~1.2    | ~1.3    | ~58%   | 性能提升 |
| 7     | ~1.0    | ~1.2    | ~65%   | 接近收敛 |
| 10    | ~0.9    | ~1.1    | ~70%   | 最终性能 |

**（注：以上数据为示例，实际结果可能因随机性和硬件而异）**

**（3）模型收敛性分析**

**收敛判断标准：**
- 测试损失连续 3-5 个 epoch 不再显著下降
- 准确率提升幅度小于 1%
- 训练损失和测试损失的差距稳定

**早停策略：**
- 如果测试损失连续多个 epoch 不再下降，可以提前停止训练
- 避免过度训练导致的过拟合
- 节省计算资源和时间

#### 2.5.4 TensorBoard 使用技巧

**（1）多实验对比**

可以同时查看多个训练实验的结果：
```bash
tensorboard --logdir=logs  # 查看所有子目录的实验
```
- 在 TensorBoard 中可以对比不同超参数的训练效果
- 便于选择最佳模型配置

**（2）图像可视化**

除了标量指标，还可以可视化图像：
```python
writer.add_image("input_images", imgs, step)
writer.add_image("feature_maps", features, step)
```
- 查看输入图像的批次
- 可视化卷积层的特征图
- 理解模型关注的重点区域

**（3）计算图可视化**

在 TensorBoard 的 GRAPHS 标签中可以查看：
- 模型的计算图结构
- 数据流向和操作顺序
- 参数依赖关系

#### 2.5.5 实验日志管理

**日志文件组织：**
```
logs/
├── events.out.tfevents.xxx.0  # TensorBoard 事件文件
├── events.out.tfevents.xxx.1
└── ...
```

**最佳实践：**
- 每次实验使用不同的日志目录，便于对比
- 日志文件名包含实验参数（如 `logs_lr0.01_batch64`）
- 定期清理旧的日志文件，节省存储空间

#### 2.5.6 典型实验结果

**预期训练结果：**

经过 10 个 epoch 的训练，模型应达到以下性能：

- **最终训练损失**：0.8 - 1.2
- **最终测试损失**：1.0 - 1.3
- **最终准确率**：65% - 75%
- **训练时间**：10-30 分钟（GPU）或 2-3 小时（CPU）

**性能分析：**

- **准确率分析**：
  - 基础 CNN 在 CIFAR-10 上的合理准确率约为 60%-75%
  - 如果准确率低于 60%，可能存在训练问题
  - 如果准确率高于 80%，可能需要验证数据集是否泄露

- **损失分析**：
  - 训练损失应持续下降，最终稳定
  - 测试损失与训练损失的差距不应过大（< 0.3）
  - 如果差距过大，说明模型过拟合

- **收敛速度**：
  - 前 3-5 个 epoch 性能提升最快
  - 后几个 epoch 性能提升缓慢
  - 如果 10 个 epoch 后仍有明显提升，可以继续训练

> **图 1：训练/测试损失与准确率曲线**（此处粘贴 TensorBoard 截图）
>
> **说明**：图中显示了训练过程中的三个关键指标：
> - 蓝色曲线：训练损失（train_loss），呈下降趋势
> - 橙色曲线：测试损失（test_loss），与训练损失接近
> - 绿色曲线：准确率（accuracy），呈上升趋势，最终达到约 70%

### 2.6 推理测试

#### 2.6.1 推理流程概述

模型推理（Inference）是使用训练好的模型对新的、未见过的图像进行预测的过程。推理过程不涉及梯度计算和参数更新，只需要前向传播。

**推理与训练的区别：**
- **训练模式**：需要计算梯度，更新参数，使用 `model.train()`
- **推理模式**：只需前向传播，使用 `model.eval()`，禁用 Dropout 和 BatchNorm 的训练行为

#### 2.6.2 模型加载

**（1）加载完整模型**

本项目使用完整模型保存方式，可以直接加载：
```python
model = torch.load("../tudui_0.pth", map_location=torch.device('cpu'))
```

**关键参数说明：**
- **文件路径**：`"../tudui_0.pth"` - 训练保存的模型文件
- **map_location**：指定加载设备
  - 如果模型在 GPU 上训练，但在 CPU 上推理，需要使用 `map_location=torch.device('cpu')`
  - 如果模型在 GPU 上训练，也要在 GPU 上推理，可以使用 `map_location=torch.device('cuda:0')`
  - 如果不指定，可能因为设备不匹配而报错

**（2）模型结构验证**

加载模型后，可以查看模型结构：
```python
print(model)
```
输出显示完整的网络结构，包括所有层的配置和参数数量。

#### 2.6.3 图像预处理

**（1）图像读取**

```python
from PIL import Image
image = Image.open(image_path)
print(image)  # 显示图像信息（格式、尺寸、模式等）
```

**图像格式说明：**
- PNG 图像可能包含 4 个通道（RGBA），包含透明度通道
- JPEG 图像通常是 3 个通道（RGB）
- 需要统一转换为 RGB 格式

**（2）格式转换**

```python
image = image.convert('RGB')  # 转换为 RGB 格式
```
- PNG 图像如果是 4 通道（RGBA），需要转换为 3 通道（RGB）
- 确保图像格式与模型输入要求一致

**（3）尺寸调整和张量转换**

```python
transform = torchvision.transforms.Compose([
    torchvision.transforms.Resize((32, 32)),  # 调整尺寸为 32×32
    torchvision.transforms.ToTensor()         # 转换为张量并归一化到 [0,1]
])
image = transform(image)
print(image.shape)  # 输出：torch.Size([3, 32, 32])
```

**预处理步骤说明：**
- **Resize((32, 32))**：将图像调整为 CIFAR-10 的标准尺寸 32×32
- **ToTensor()**：将 PIL 图像转换为 PyTorch 张量
  - 自动将像素值从 [0, 255] 归一化到 [0, 1]
  - 将图像维度从 (H, W, C) 转换为 (C, H, W)
  - 数据类型从 uint8 转换为 float32

**（4）添加批次维度**

```python
image = torch.reshape(image, (1, 3, 32, 32))
# 或者使用 unsqueeze
image = image.unsqueeze(0)  # 在维度 0 添加一个维度
```

**维度说明：**
- 模型输入要求：`(batch_size, channels, height, width)`
- 单张图像需要添加批次维度：`(1, 3, 32, 32)`
- batch_size=1 表示批次中只有一张图像

#### 2.6.4 模型推理

**（1）设置为评估模式**

```python
model.eval()  # 设置为评估模式
```

**评估模式的作用：**
- 禁用 Dropout 层（使用所有神经元）
- BatchNorm 使用训练时统计的均值和方差，而不是当前批次的统计值
- 确保推理结果的一致性

**（2）前向传播**

```python
with torch.no_grad():  # 禁用梯度计算
    output = model(image)
```

**关键点说明：**
- **torch.no_grad()**：禁用自动求导机制
  - 节省内存：不保存计算图
  - 加速计算：跳过梯度计算过程
  - 推理时不需要梯度，因此必须使用

- **前向传播**：图像经过 CNN 网络，得到 10 个类别的 logits 输出
  - 输入：`(1, 3, 32, 32)` - 单张图像
  - 输出：`(1, 10)` - 10 个类别的原始分数（logits）

#### 2.6.5 结果解析

**（1）输出 logits**

```python
print(output)
# 输出示例：tensor([[2.1, 0.5, -0.3, 1.8, 0.2, -0.1, 0.9, 0.3, 1.2, 0.7]])
```

**logits 说明：**
- logits 是模型输出的原始分数，未经 Softmax 归一化
- 数值越大，表示模型认为该类别越可能
- 10 个数值对应 10 个类别

**（2）获取预测类别**

```python
predicted_class = output.argmax(1)
print(predicted_class)  # 输出：tensor([0]) 或 tensor([3]) 等
```

**argmax 操作：**
- `argmax(1)` 在维度 1（类别维度）上找到最大值的位置
- 返回预测类别的索引（0-9）
- 这是最直接的分类决策方法

**（3）类别索引到名称映射**

CIFAR-10 数据集的类别顺序：
```python
classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 
           'dog', 'frog', 'horse', 'ship', 'truck']
predicted_name = classes[predicted_class.item()]
print(f"预测类别：{predicted_name}")
```

**类别映射：**
- 索引 0 → 'airplane'（飞机）
- 索引 1 → 'automobile'（汽车）
- 索引 2 → 'bird'（鸟）
- 索引 3 → 'cat'（猫）
- 索引 4 → 'deer'（鹿）
- 索引 5 → 'dog'（狗）
- 索引 6 → 'frog'（青蛙）
- 索引 7 → 'horse'（马）
- 索引 8 → 'ship'（船）
- 索引 9 → 'truck'（卡车）

**（4）概率计算（可选）**

如果需要查看每个类别的概率：
```python
import torch.nn.functional as F
probabilities = F.softmax(output, dim=1)
print(probabilities)
# 输出：tensor([[0.15, 0.05, 0.02, 0.25, 0.03, 0.02, 0.08, 0.04, 0.18, 0.18]])
```

**Softmax 函数：**
- 将 logits 转换为概率分布
- 所有概率之和为 1
- 概率最大的类别即为预测结果

#### 2.6.6 推理脚本完整流程

**完整推理代码示例：**

```python
import torch
import torchvision.transforms
from PIL import Image
from torch import nn

# 1. 加载模型
model = torch.load("../tudui_0.pth", map_location=torch.device('cpu'))
model.eval()

# 2. 加载和预处理图像
image_path = "../img/airplane.PNG"
image = Image.open(image_path)
image = image.convert('RGB')

transform = torchvision.transforms.Compose([
    torchvision.transforms.Resize((32, 32)),
    torchvision.transforms.ToTensor()
])
image = transform(image)
image = image.unsqueeze(0)  # 添加批次维度

# 3. 模型推理
with torch.no_grad():
    output = model(image)

# 4. 结果解析
predicted_class = output.argmax(1)
classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 
           'dog', 'frog', 'horse', 'ship', 'truck']
predicted_name = classes[predicted_class.item()]

print(f"输入图像：{image_path}")
print(f"预测类别索引：{predicted_class.item()}")
print(f"预测类别名称：{predicted_name}")
print(f"输出 logits：{output}")
```

#### 2.6.7 推理性能优化

**（1）批量推理**

如果有多张图像需要预测，可以使用批量推理：
```python
# 将多张图像堆叠成批次
batch_images = torch.stack([img1, img2, img3, ...])
with torch.no_grad():
    batch_outputs = model(batch_images)
```

**优势：**
- 充分利用 GPU 并行计算能力
- 减少数据传输开销
- 提高推理效率

**（2）GPU 加速**

如果使用 GPU 推理：
```python
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
model = model.to(device)
image = image.to(device)

with torch.no_grad():
    output = model(image)
```

**性能提升：**
- GPU 推理速度通常是 CPU 的 10-50 倍
- 特别适合批量推理场景

**（3）模型量化（可选）**

为了进一步加速推理，可以使用模型量化：
- 将 float32 转换为 int8
- 减少模型大小和推理时间
- 可能略微降低精度

#### 2.6.8 推理结果验证

**（1）单张图像测试**

使用 `src/test.py` 脚本测试单张图像：
```bash
python src/test.py
```

**输出内容：**
- 图像信息（尺寸、格式）
- 模型结构
- 输出 logits（10 个数值）
- 预测类别索引

**（2）批量测试**

可以在测试集上评估模型：
```python
correct = 0
total = 0
with torch.no_grad():
    for images, labels in test_dataloader:
        outputs = model(images)
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

accuracy = 100 * correct / total
print(f'测试集准确率：{accuracy:.2f}%')
```

- **插图位（单张推理）**：
  - 原图（缩略图）+ 终端输出（logits 与 `argmax`）的截图拼接；
  - 若方便，可补充将 `argmax` 索引映射到 `classes` 名称的打印结果。

> **图 2：单张图片预测结果**（终端输出截图 + 可选可视化）
>
> **说明**：
> - 左上：原始输入图像（airplane.PNG）
> - 右上：图像预处理后的形状 `torch.Size([3, 32, 32])`
> - 下方：模型输出 logits 和预测类别索引
> - 预测结果：类别索引 0，对应 'airplane'（飞机），预测正确

### 2.7 迁移到 VGG16（可选）
- 将模型替换为 `torchvision.models.vgg16`
- 调整分类头：`vgg.classifier[6] = nn.Linear(4096, 10)`
- 调整输入变换为 ImageNet 规范（Resize/Crop/Normalize）
- 微调策略：先冻住特征层，仅训练分类头；或小学习率端到端训练。

- 插图位（对比曲线）：若做了 VGG16 实验，展示与基础 CNN 的曲线对比（loss/accuracy），给出简短结论。

> 图 3：VGG16 训练的对比曲线（如有）

---

## 三、心得体会

- **难点与解决思路**：
  - 数据与维度匹配：确保输入尺寸（32×32×3）与 `Linear(1024, 64)` 的展平尺寸一致；
  - 设备管理：使用 `.to(device)` 统一管理模型、数据、损失函数到 GPU；
  - 可视化与调参：通过 TensorBoard 观察过拟合迹象，适当调整学习率或加入数据增强。
- **知识技能收获**：
  - 掌握 PyTorch 数据管线（Dataset/DataLoader）与训练循环；
  - 学会使用 TensorBoard 进行指标可视化；
  - 了解模型保存/加载与迁移学习的基本流程。
- **反思与感悟**：
  - 基础 CNN 在 CIFAR-10 上能较快收敛，但对数据增强和正则化较为敏感；
  - 结构越简单，复现实验越稳健；在此基础上再逐步引入改进手段更靠谱。

- 插图位（对比/问题定位，可选）：
  - 若有不同学习率/批大小或数据增强设置的对比曲线，贴出并配 1~2 句说明；
  - 可放一张“训练异常或 bug” 的现象截图 + 解决前后对比（体现调试过程）。

---

## 四、总结与展望

- **项目成果**：
  - 基于 PyTorch 完成 CIFAR-10 十分类的从训练到推理的完整实现；
  - 训练日志与模型权重可复现；提供推理脚本用于快速验证。
- **不足**：
  - 基础 CNN 模型表达能力有限；
  - 数据增强与正则化策略较简单；
  - 未进行系统的超参数搜索。
- **改进方向**：
  - 引入 BatchNorm/Dropout、数据增强（RandomCrop/Flip/ColorJitter）；
  - 尝试更强模型（ResNet、DenseNet）与学习率调度器；
  - 系统化实验对比与 ablation study，并整理更规范的复现实验脚本。

- 插图位（成果总览）：
  - 最终最佳 `accuracy` 曲线终点截图 + 根目录 `tudui_*.pth` 文件列表截屏（体现多轮保存与成果产出）。
- 代码块位（改进方向关键行，可选）：
  - `vgg = torchvision.models.vgg16(weights='IMAGENET1K_V1')`
  - `vgg.classifier[6] = nn.Linear(4096, 10)`

---

- 附：运行指令速览
  - 训练（CPU）：`python train.py`
  - 训练（GPU）：`python train_gpu_2.py`
  - 可视化：`tensorboard --logdir=logs`
  - 推理：`python src/test.py`
